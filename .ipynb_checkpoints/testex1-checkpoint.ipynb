{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单变量线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:19.560787Z",
     "start_time": "2021-04-27T06:16:19.551147Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:19.591228Z",
     "start_time": "2021-04-27T06:16:19.563276Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导入数据，并查看\n",
    "path = 'ex1data1.txt'\n",
    "names = ['Population', 'Profit']\n",
    "data = pd.read_csv(path, header=None, names=names)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:19.621123Z",
     "start_time": "2021-04-27T06:16:19.593196Z"
    }
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:19.715727Z",
     "start_time": "2021-04-27T06:16:19.624130Z"
    }
   },
   "outputs": [],
   "source": [
    "# 在开始任何任务之前，通过可视化来理解数据通常是有用的。\n",
    "# 对于这个数据集，可以使用散点图来可视化数据，因为它只有两个属性(利润和人口)。\n",
    "# (在现实生活中遇到的许多其他问题都是多维度的，不能在二维图上画出来。)\n",
    "data.plot(kind='scatter', x='Population', y='Profit', figsize=(8, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:19.730690Z",
     "start_time": "2021-04-27T06:16:19.717779Z"
    }
   },
   "outputs": [],
   "source": [
    "# 使用梯度下降来实现线性回归，以最小化成本函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:19.745646Z",
     "start_time": "2021-04-27T06:16:19.732682Z"
    }
   },
   "outputs": [],
   "source": [
    "# 计算代价函数\n",
    "def computeCost(X, y, theta):\n",
    "    return np.sum(np.power(X.dot(theta.T)-y, 2))/(2*len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:19.760606Z",
     "start_time": "2021-04-27T06:16:19.748638Z"
    }
   },
   "outputs": [],
   "source": [
    "# 在训练集中添加一列，以便我们可以使用向量化的解决方案来计算代价和梯度\n",
    "data.insert(0, 'Ones', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:19.775623Z",
     "start_time": "2021-04-27T06:16:19.761603Z"
    }
   },
   "outputs": [],
   "source": [
    "# 变量初始化\n",
    "# set X (training data) and y (target variable)\n",
    "cols = data.shape[1]  # 列数\n",
    "X = data.iloc[:, 0:cols-1]  # 取前cols-1列，即输入向量\n",
    "y = data.iloc[:, cols-1:cols]  # 取最后一列，即目标向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:19.791647Z",
     "start_time": "2021-04-27T06:16:19.776649Z"
    }
   },
   "outputs": [],
   "source": [
    "# 观察下 X (训练集) and y (目标变量)是否正确\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:19.807538Z",
     "start_time": "2021-04-27T06:16:19.792578Z"
    }
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:19.822498Z",
     "start_time": "2021-04-27T06:16:19.812528Z"
    }
   },
   "outputs": [],
   "source": [
    "# 转换X和Y，初始化theta\n",
    "X = np.matrix(X.values)\n",
    "y = np.matrix(y.values)\n",
    "theta = np.matrix([0, 0])\n",
    "X.shape, theta.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:19.837485Z",
     "start_time": "2021-04-27T06:16:19.824495Z"
    }
   },
   "outputs": [],
   "source": [
    "# 算初始代价函数的值 (theta初始值为0)\n",
    "computeCost(X, y, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:19.852418Z",
     "start_time": "2021-04-27T06:16:19.838483Z"
    }
   },
   "outputs": [],
   "source": [
    "# batch gradient decent（批量梯度下降）\n",
    "def gradientDescent(X, y, theta, alpha, epoch):\n",
    "    temp = np.matrix(np.zeros(theta.shape))  # 初始化一个 θ 临时矩阵\n",
    "    cost = np.zeros(epoch)  # 初始化一个ndarray，包含每次epoch的cost\n",
    "    m = X.shape[0]  # 样本数量m\n",
    "\n",
    "    for i in range(epoch):\n",
    "        temp = theta - (alpha/m)*np.dot((X.dot(theta.T)-y).T, X)\n",
    "        theta = temp\n",
    "        cost[i] = computeCost(X, y, theta)\n",
    "    return theta, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:19.867405Z",
     "start_time": "2021-04-27T06:16:19.853450Z"
    }
   },
   "outputs": [],
   "source": [
    "# 初始化一些附加变量 - 学习速率α和要执行的迭代次数\n",
    "alpha = 0.01\n",
    "epoch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:19.914318Z",
     "start_time": "2021-04-27T06:16:19.869411Z"
    }
   },
   "outputs": [],
   "source": [
    "# 运行梯度下降算法来使参数θ适合于训练集\n",
    "final_theta, cost = gradientDescent(X, y, theta, alpha, epoch)\n",
    "final_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:19.930210Z",
     "start_time": "2021-04-27T06:16:19.915285Z"
    }
   },
   "outputs": [],
   "source": [
    "# 使用拟合的参数计算训练模型的代价函数（误差）\n",
    "computeCost(X, y, final_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:20.037923Z",
     "start_time": "2021-04-27T06:16:19.932207Z"
    }
   },
   "outputs": [],
   "source": [
    "# 绘制线性模型以及数据，直观地看出它的拟合\n",
    "x = np.linspace(data.Population.min(), data.Population.max(), 100)  # 横坐标\n",
    "f = final_theta[0, 0]+(final_theta[0, 1]*x)  # 纵坐标\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot(x, f, 'r', label='Prediction')\n",
    "ax.scatter(data.Population, data.Profit, label='Training Data')\n",
    "ax.legend(loc='best')\n",
    "ax.set_xlabel('Population')\n",
    "ax.set_ylabel('Profit')\n",
    "ax.set_title('Predicted Profit vs. Population Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:20.132463Z",
     "start_time": "2021-04-27T06:16:20.039919Z"
    }
   },
   "outputs": [],
   "source": [
    "# 由于梯度方程式函数也在每个训练迭代中输出一个代价的向量，所以我们也可以绘制。 请注意，线性回归中的代价函数总是降低的 - 这是凸优化问题的一个例子。\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(np.arange(epoch), cost, 'r')\n",
    "ax.set_xlabel('Iterations')\n",
    "ax.set_ylabel('Cost')\n",
    "ax.set_title('Error vs. Training Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多变量线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:20.148469Z",
     "start_time": "2021-04-27T06:16:20.133459Z"
    }
   },
   "outputs": [],
   "source": [
    "path = 'ex1data2.txt'\n",
    "names = ['Size', 'Bedrooms', 'Price']\n",
    "data2 = pd.read_csv(path, header=None, names=names)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:20.164340Z",
     "start_time": "2021-04-27T06:16:20.150417Z"
    }
   },
   "outputs": [],
   "source": [
    "# 特征归一化\n",
    "data2=(data2-data2.mean())/data2.std()\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:20.211244Z",
     "start_time": "2021-04-27T06:16:20.165338Z"
    }
   },
   "outputs": [],
   "source": [
    "# add ones column\n",
    "data2.insert(0, 'Ones', 1)\n",
    "\n",
    "# set X (training data) and y (target variable)\n",
    "cols = data2.shape[1]\n",
    "X2 = data2.iloc[:, 0:cols-1]\n",
    "y2 = data2.iloc[:, cols-1:cols]\n",
    "\n",
    "# convert to matrices and initialize theta\n",
    "X2 = np.matrix(X2.values)\n",
    "y2 = np.matrix(y2.values)\n",
    "theta2 = np.matrix(np.array([0, 0, 0]))\n",
    "\n",
    "# perform linear regression on the data set\n",
    "final_theta2, cost2=gradientDescent(X2, y2, theta2, alpha, epoch)\n",
    "\n",
    "# get the cost (error) of the model\n",
    "computeCost(X2, y2, final_theta2)\n",
    "final_theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:20.319444Z",
     "start_time": "2021-04-27T06:16:20.213252Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(12,8))\n",
    "ax.plot(np.arange(epoch),cost2,'r')\n",
    "ax.set_xlabel('Iterations')\n",
    "ax.set_ylabel('Cost')\n",
    "ax.set_title('Error vs. Training Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:20.335391Z",
     "start_time": "2021-04-27T06:16:20.321379Z"
    }
   },
   "outputs": [],
   "source": [
    "# # 使用scikit-learn的线性回归函数，而不是从头开始实现这些算法\n",
    "# from sklearn import  linear_model\n",
    "# model=linear_model.LinearRegression()\n",
    "# model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normal equation（正规方程）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:20.351299Z",
     "start_time": "2021-04-27T06:16:20.338349Z"
    }
   },
   "outputs": [],
   "source": [
    "# 正规方程\n",
    "def normalEqn(X,y):\n",
    "    theta=np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T06:16:20.366714Z",
     "start_time": "2021-04-27T06:16:20.352297Z"
    }
   },
   "outputs": [],
   "source": [
    "fintheta=normalEqn(X,y)\n",
    "fintheta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
